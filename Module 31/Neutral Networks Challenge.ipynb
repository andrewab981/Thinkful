{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Use RBM to perform feature extraction on an image-based dataset that you find or create. If you go this route, present the features you extract and explain why this is a useful feature extraction method in the context you’re operating in. DO NOT USE either the MNIST digit recognition database or the iris data set. They’ve been worked on in very public ways very very many times and the code is easily available. (However, that code could be a useful resource to refer to).\n",
    "\n",
    "## Import the Data and Cleaning\n",
    "\n",
    "https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lungs(data_path, categories, img_size):\n",
    "    \"\"\"Build dataset of x-rays\n",
    "    Parameters:\n",
    "    data_path(str): file location\n",
    "    categories(str): folders within file location\n",
    "    img_size(int): dimensions of image\n",
    "    \n",
    "    Returns:\n",
    "    Tuple of the data and targets\"\"\"\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for category in categories:\n",
    "        #path to images\n",
    "        path = os.path.join(data_path, category)\n",
    "        # image identifer 0 for normal, 1 for pneumonia\n",
    "        class_num = categories.index(category)\n",
    "        \n",
    "        for img in os.listdir(path):    \n",
    "            # append each image to array apply grayscale\n",
    "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # uniform image shape for all x-rays\n",
    "            new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "           \n",
    "            data.append([new_array, class_num])\n",
    "    \n",
    "    # randomize the data to reduce bias\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_target(dataset):\n",
    "    \"\"\"Append features and target variables\n",
    "    Parameters:\n",
    "    dataset(array): dataset that will be split\n",
    "    \n",
    "    Returns: X and y variables for modeling\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for features, label in dataset:\n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    #X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 624 x-rays.\n",
      "\n",
      "--- 6.761709690093994 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data_path = 'pneumonia_data/test'\n",
    "categories = ['NORMAL', 'PNEUMONIA']\n",
    "img_size = 1500\n",
    "\n",
    "train_set = load_lungs(data_path, categories, img_size)\n",
    "print('Loaded {} x-rays.'.format(len(train_set)))\n",
    "\n",
    "X_train, y_train = feature_target(train_set)\n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 624 x-rays.\n",
      "\n",
      "--- 0.20566725730895996 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data_path = 'pneumonia_data/val'\n",
    "\n",
    "test_set = load_lungs(data_path, categories, img_size)\n",
    "print('Loaded {} x-rays.'.format(len(test_set)))\n",
    "\n",
    "X_test, y_test = feature_target(test_set)\n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "rbm = BernoulliRBM()\n",
    "rbm = rbm.fit(X_train, y_train)\n",
    "print('Training Set Fitted')\n",
    "\n",
    "pred_train = rbm.predict(X_train)\n",
    "pred_test = rbm.predict(X_test)\n",
    "print('Test Set Predicted')\n",
    "\n",
    "# Print results of test and train data\n",
    "print('Cross Validation of Training Set:')\n",
    "print(cross_val_score(neighbors, X_train, y_train, cv=5))\n",
    "print('\\nCross Validation of Test Set:')\n",
    "print(cross_val_score(neighbors, X_test, y_test, cv=5))\n",
    "\n",
    "print('\\nAccuracy Score of Training Set: {}\\n'.format(accuracy_score(y_train, pred_train)))\n",
    "print('Accuracy Score of Test Set: {}'.format(accuracy_score(y_test, pred_test)))\n",
    "print(\"\\n--- %s seconds ---\" % (time.time() - start_time))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heatmap of confusion matrix\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.heatmap(confusion_matrix(y_train, pred_train), annot=True, fmt='g')\n",
    "\n",
    "plt.ylabel('True Label', fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontweight='bold')\n",
    "plt.title('Confusion Matrix of Training Set', fontweight='bold')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(confusion_matrix(y_test, pred_test), annot=True, fmt='g')\n",
    "\n",
    "plt.ylabel('True Label', fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontweight='bold')\n",
    "plt.title('Confusion Matrix of Test Set', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
